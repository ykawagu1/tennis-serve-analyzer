#!/usr/bin/env python3
"""
ãƒ†ãƒ‹ã‚¹ã‚µãƒ¼ãƒ“ã‚¹å‹•ä½œè§£æ - çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å‹•ç”»å‡¦ç†ã€ãƒãƒ¼ã‚ºæ¤œå‡ºã€å‹•ä½œè§£æã®çµ±åˆãƒ†ã‚¹ãƒˆ
"""

import sys
import os
import json
import time
from pathlib import Path
from typing import Dict

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), 'app'))

from services.video_processor import VideoProcessor
from services.pose_detector import PoseDetector
from services.motion_analyzer import MotionAnalyzer


class TennisServeAnalyzer:
    """ãƒ†ãƒ‹ã‚¹ã‚µãƒ¼ãƒ“ã‚¹è§£æã®çµ±åˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """è§£æå™¨ã®åˆæœŸåŒ–"""
        self.video_processor = VideoProcessor()
        self.pose_detector = PoseDetector()
        self.motion_analyzer = MotionAnalyzer()
        
        print("ãƒ†ãƒ‹ã‚¹ã‚µãƒ¼ãƒ“ã‚¹è§£æå™¨ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
    
    def analyze_video(self, video_path: str, output_dir: str = "output") -> Dict:
        """
        å‹•ç”»ã®åŒ…æ‹¬çš„è§£æ
        
        Args:
            video_path: å…¥åŠ›å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            è§£æçµæœã®è¾æ›¸
        """
        print(f"=== å‹•ç”»è§£æé–‹å§‹: {video_path} ===")
        start_time = time.time()
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(output_dir, exist_ok=True)
        
        try:
            # Step 1: å‹•ç”»æ¤œè¨¼
            print("\n1. å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ä¸­...")
            validation_result = self.video_processor.validate_video(video_path)
            
            if not validation_result['is_valid']:
                raise ValueError(f"å‹•ç”»æ¤œè¨¼å¤±æ•—: {validation_result['error_message']}")
            
            print("âœ“ å‹•ç”»æ¤œè¨¼å®Œäº†")
            if validation_result['warnings']:
                for warning in validation_result['warnings']:
                    print(f"  è­¦å‘Š: {warning}")
            
            # Step 2: å‹•ç”»å‰å‡¦ç†
            print("\n2. å‹•ç”»å‰å‡¦ç†ä¸­...")
            preprocessed_path = self.video_processor.preprocess_video(
                video_path, 
                os.path.join(output_dir, "preprocessed_video.mp4")
            )
            print(f"âœ“ å‰å‡¦ç†å®Œäº†: {preprocessed_path}")
            
            # Step 3: ãƒãƒ¼ã‚ºæ¤œå‡º
            print("\n3. ãƒãƒ¼ã‚ºæ¤œå‡ºå®Ÿè¡Œä¸­...")
            pose_results = self.pose_detector.process_video(
                preprocessed_path,
                os.path.join(output_dir, "pose_visualization.mp4")
            )
            
            # ãƒãƒ¼ã‚ºãƒ‡ãƒ¼ã‚¿ä¿å­˜
            pose_data_path = os.path.join(output_dir, "pose_data.json")
            self.pose_detector.save_pose_data(pose_results, pose_data_path)
            print(f"âœ“ ãƒãƒ¼ã‚ºæ¤œå‡ºå®Œäº†: {len(pose_results)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
            
            # ãƒãƒ¼ã‚ºæ¤œå‡ºçµ±è¨ˆ
            pose_stats = self.pose_detector.get_pose_statistics(pose_results)
            print(f"  æ¤œå‡ºç‡: {pose_stats['detection_rate']:.1%}")
            print(f"  å¹³å‡ä¿¡é ¼åº¦: {pose_stats['average_confidence']:.3f}")
            
            # Step 4: å‹•ä½œè§£æ
            print("\n4. å‹•ä½œè§£æå®Ÿè¡Œä¸­...")
            analysis_result = self.motion_analyzer.analyze_serve_motion(pose_results)
            
            # è§£æçµæœä¿å­˜
            analysis_result_path = os.path.join(output_dir, "analysis_result.json")
            with open(analysis_result_path, 'w', encoding='utf-8') as f:
                json.dump(analysis_result, f, indent=2, ensure_ascii=False)
            
            print(f"âœ“ å‹•ä½œè§£æå®Œäº†")
            print(f"  ç·åˆã‚¹ã‚³ã‚¢: {analysis_result['overall_score']:.1f}/10.0")
            
            # Step 5: çµæœã‚µãƒãƒªãƒ¼ç”Ÿæˆ
            summary = self._generate_summary(
                validation_result, 
                pose_stats, 
                analysis_result
            )
            
            summary_path = os.path.join(output_dir, "analysis_summary.json")
            with open(summary_path, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            # å‡¦ç†æ™‚é–“è¨ˆç®—
            total_time = time.time() - start_time
            print(f"\n=== è§£æå®Œäº† (å‡¦ç†æ™‚é–“: {total_time:.1f}ç§’) ===")
            
            return {
                'success': True,
                'output_directory': output_dir,
                'processing_time': total_time,
                'files': {
                    'preprocessed_video': preprocessed_path,
                    'pose_visualization': os.path.join(output_dir, "pose_visualization.mp4"),
                    'pose_data': pose_data_path,
                    'analysis_result': analysis_result_path,
                    'summary': summary_path
                },
                'analysis_result': analysis_result,
                'summary': summary
            }
            
        except Exception as e:
            error_message = f"è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            print(f"\nâŒ {error_message}")
            
            return {
                'success': False,
                'error_message': error_message,
                'processing_time': time.time() - start_time
            }
        
        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self.video_processor.cleanup_temp_files()
    
    def _generate_summary(self, validation_result: Dict, pose_stats: Dict, analysis_result: Dict) -> Dict:
        """è§£æçµæœã®ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        
        # æŠ€è¡“è¦ç´ åˆ¥ã‚¹ã‚³ã‚¢æŠ½å‡º
        technical_scores = {}
        key_issues = []
        recommendations = []
        
        for category, results in analysis_result['technical_analysis'].items():
            technical_scores[category] = results.get('overall_score', 0.0)
            
            if 'issues' in results:
                key_issues.extend(results['issues'])
            
            if 'recommendations' in results:
                recommendations.extend(results['recommendations'])
        
        # ã‚µãƒ¼ãƒ–ãƒ•ã‚§ãƒ¼ã‚ºæƒ…å ±
        phase_info = {}
        for phase_name, phase_data in analysis_result['serve_phases'].items():
            phase_info[phase_name] = {
                'duration': phase_data['duration'],
                'frame_range': f"{phase_data['start_frame']}-{phase_data['end_frame']}"
            }
        
        return {
            'analysis_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'video_info': validation_result['metadata'],
            'pose_detection': {
                'detection_rate': pose_stats['detection_rate'],
                'average_confidence': pose_stats['average_confidence'],
                'total_frames': pose_stats['total_frames'],
                'detected_frames': pose_stats['detected_frames']
            },
            'overall_score': analysis_result['overall_score'],
            'technical_scores': technical_scores,
            'serve_phases': phase_info,
            'key_issues': key_issues[:5],  # ä¸Šä½5ã¤ã®å•é¡Œç‚¹
            'recommendations': recommendations[:5],  # ä¸Šä½5ã¤ã®æ¨å¥¨äº‹é …
            'performance_level': self._classify_performance_level(analysis_result['overall_score'])
        }
    
    def _classify_performance_level(self, overall_score: float) -> str:
        """ç·åˆã‚¹ã‚³ã‚¢ã‹ã‚‰ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ã‚’åˆ†é¡"""
        if overall_score >= 8.5:
            return "ä¸Šç´šè€…"
        elif overall_score >= 7.0:
            return "ä¸­ç´šè€…"
        elif overall_score >= 5.5:
            return "åˆä¸­ç´šè€…"
        elif overall_score >= 4.0:
            return "åˆç´šè€…"
        else:
            return "åˆå¿ƒè€…"
    
    def print_analysis_summary(self, result: Dict):
        """è§£æçµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        if not result['success']:
            print(f"âŒ è§£æå¤±æ•—: {result['error_message']}")
            return
        
        summary = result['summary']
        
        print("\n" + "="*60)
        print("           ãƒ†ãƒ‹ã‚¹ã‚µãƒ¼ãƒ“ã‚¹è§£æçµæœã‚µãƒãƒªãƒ¼")
        print("="*60)
        
        print(f"\nğŸ“¹ å‹•ç”»æƒ…å ±:")
        video_info = summary['video_info']
        print(f"  ãƒ•ã‚¡ã‚¤ãƒ«å: {video_info['filename']}")
        print(f"  è§£åƒåº¦: {video_info['width']}x{video_info['height']}")
        print(f"  æ™‚é–“: {video_info['duration']:.1f}ç§’")
        print(f"  ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ: {video_info['fps']:.1f}fps")
        
        print(f"\nğŸ¯ ãƒãƒ¼ã‚ºæ¤œå‡º:")
        pose_info = summary['pose_detection']
        print(f"  æ¤œå‡ºç‡: {pose_info['detection_rate']:.1%}")
        print(f"  å¹³å‡ä¿¡é ¼åº¦: {pose_info['average_confidence']:.3f}")
        print(f"  å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {pose_info['detected_frames']}/{pose_info['total_frames']}")
        
        print(f"\nğŸ“Š ç·åˆè©•ä¾¡:")
        print(f"  ç·åˆã‚¹ã‚³ã‚¢: {summary['overall_score']:.1f}/10.0")
        print(f"  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«: {summary['performance_level']}")
        
        print(f"\nğŸ“ˆ æŠ€è¡“è¦ç´ åˆ¥ã‚¹ã‚³ã‚¢:")
        for category, score in summary['technical_scores'].items():
            category_name = {
                'knee_movement': 'è†ã®å‹•ã',
                'elbow_position': 'è‚˜ã®ä½ç½®',
                'toss_trajectory': 'ãƒˆã‚¹è»Œé“',
                'body_rotation': 'ä½“ã®å›è»¢',
                'timing': 'ã‚¿ã‚¤ãƒŸãƒ³ã‚°'
            }.get(category, category)
            print(f"  {category_name}: {score:.1f}/10.0")
        
        print(f"\nâš ï¸  ä¸»ãªæ”¹å–„ç‚¹:")
        for i, issue in enumerate(summary['key_issues'], 1):
            print(f"  {i}. {issue}")
        
        print(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
        for i, recommendation in enumerate(summary['recommendations'], 1):
            print(f"  {i}. {recommendation}")
        
        print(f"\nğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
        for file_type, file_path in result['files'].items():
            file_name = {
                'preprocessed_video': 'å‰å‡¦ç†æ¸ˆã¿å‹•ç”»',
                'pose_visualization': 'ãƒãƒ¼ã‚ºå¯è¦–åŒ–å‹•ç”»',
                'pose_data': 'ãƒãƒ¼ã‚ºãƒ‡ãƒ¼ã‚¿',
                'analysis_result': 'è©³ç´°è§£æçµæœ',
                'summary': 'ã‚µãƒãƒªãƒ¼'
            }.get(file_type, file_type)
            print(f"  {file_name}: {file_path}")
        
        print(f"\nâ±ï¸  å‡¦ç†æ™‚é–“: {result['processing_time']:.1f}ç§’")
        print("="*60)


def create_sample_video():
    """ãƒ†ã‚¹ãƒˆç”¨ã®ã‚µãƒ³ãƒ—ãƒ«å‹•ç”»ã‚’ä½œæˆ"""
    import cv2
    import numpy as np
    
    # ã‚µãƒ³ãƒ—ãƒ«å‹•ç”»ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    width, height = 640, 480
    fps = 30
    duration = 5  # 5ç§’
    total_frames = fps * duration
    
    output_path = "sample_tennis_serve.mp4"
    
    # å‹•ç”»ãƒ©ã‚¤ã‚¿ãƒ¼è¨­å®š
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    print(f"ã‚µãƒ³ãƒ—ãƒ«å‹•ç”»ä½œæˆä¸­: {output_path}")
    
    try:
        for frame_num in range(total_frames):
            # èƒŒæ™¯ä½œæˆï¼ˆãƒ†ãƒ‹ã‚¹ã‚³ãƒ¼ãƒˆé¢¨ï¼‰
            frame = np.zeros((height, width, 3), dtype=np.uint8)
            frame[:] = (34, 139, 34)  # ç·‘è‰²ã®èƒŒæ™¯
            
            # ç°¡å˜ãªäººå‹ã®æç”»ï¼ˆã‚µãƒ¼ãƒ–å‹•ä½œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
            progress = frame_num / total_frames
            
            # ä½“ã®ä¸­å¿ƒä½ç½®
            center_x = width // 2
            center_y = height // 2 + 50
            
            # ã‚µãƒ¼ãƒ–å‹•ä½œã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            if progress < 0.2:  # æº–å‚™ãƒ•ã‚§ãƒ¼ã‚º
                arm_angle = 0
                knee_bend = 0
            elif progress < 0.4:  # ãƒˆã‚¹ãƒ•ã‚§ãƒ¼ã‚º
                arm_angle = progress * 90
                knee_bend = progress * 20
            elif progress < 0.6:  # ãƒˆãƒ­ãƒ•ã‚£ãƒ¼ãƒã‚¸ã‚·ãƒ§ãƒ³
                arm_angle = 90 + (progress - 0.4) * 45
                knee_bend = 20 + (progress - 0.4) * 30
            elif progress < 0.8:  # åŠ é€Ÿãƒ•ã‚§ãƒ¼ã‚º
                arm_angle = 135 + (progress - 0.6) * 90
                knee_bend = 50 - (progress - 0.6) * 40
            else:  # ãƒ•ã‚©ãƒ­ãƒ¼ã‚¹ãƒ«ãƒ¼
                arm_angle = 225 + (progress - 0.8) * 45
                knee_bend = 10 - (progress - 0.8) * 10
            
            # äººå‹ã®æç”»
            # é ­
            cv2.circle(frame, (center_x, center_y - 80), 20, (255, 255, 255), -1)
            
            # ä½“
            cv2.line(frame, (center_x, center_y - 60), (center_x, center_y + 40), (255, 255, 255), 3)
            
            # è…•ï¼ˆå³è…•ã®ã‚µãƒ¼ãƒ–å‹•ä½œï¼‰
            arm_length = 60
            arm_x = center_x + int(arm_length * np.cos(np.radians(arm_angle)))
            arm_y = center_y - 20 + int(arm_length * np.sin(np.radians(arm_angle)))
            cv2.line(frame, (center_x, center_y - 20), (arm_x, arm_y), (255, 255, 255), 3)
            
            # å·¦è…•ï¼ˆãƒˆã‚¹ï¼‰
            left_arm_y = center_y - 20 - int(30 * progress) if progress < 0.4 else center_y - 20 - int(30 * (0.8 - progress))
            cv2.line(frame, (center_x, center_y - 20), (center_x - 40, left_arm_y), (255, 255, 255), 3)
            
            # è„šï¼ˆè†ã®æ›²ã’ï¼‰
            leg_y = center_y + 40 + int(knee_bend)
            cv2.line(frame, (center_x, center_y + 40), (center_x - 20, leg_y), (255, 255, 255), 3)
            cv2.line(frame, (center_x, center_y + 40), (center_x + 20, leg_y), (255, 255, 255), 3)
            
            # ãƒœãƒ¼ãƒ«ï¼ˆãƒˆã‚¹ä¸­ã®ã¿ï¼‰
            if 0.2 <= progress <= 0.6:
                ball_height = center_y - 20 - int(100 * np.sin(np.pi * (progress - 0.2) / 0.4))
                cv2.circle(frame, (center_x - 40, ball_height), 5, (0, 255, 255), -1)
            
            out.write(frame)
            
            # é€²æ—è¡¨ç¤º
            if frame_num % 30 == 0:
                print(f"é€²æ—: {(frame_num / total_frames) * 100:.1f}%")
    
    finally:
        out.release()
    
    print(f"ã‚µãƒ³ãƒ—ãƒ«å‹•ç”»ä½œæˆå®Œäº†: {output_path}")
    return output_path


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ãƒ†ãƒ‹ã‚¹ã‚µãƒ¼ãƒ“ã‚¹å‹•ä½œè§£æã‚·ã‚¹ãƒ†ãƒ  - çµ±åˆãƒ†ã‚¹ãƒˆ")
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å‡¦ç†
    if len(sys.argv) > 1:
        video_path = sys.argv[1]
    else:
        # ã‚µãƒ³ãƒ—ãƒ«å‹•ç”»ã‚’ä½œæˆ
        print("\nå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µãƒ³ãƒ—ãƒ«å‹•ç”»ã‚’ä½œæˆã—ã¾ã™...")
        video_path = create_sample_video()
    
    if not os.path.exists(video_path):
        print(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}")
        return
    
    # è§£æå™¨ã®åˆæœŸåŒ–
    analyzer = TennisServeAnalyzer()
    
    # è§£æå®Ÿè¡Œ
    result = analyzer.analyze_video(video_path)
    
    # çµæœè¡¨ç¤º
    analyzer.print_analysis_summary(result)
    
    if result['success']:
        print(f"\nâœ… è§£æãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸã€‚")
        print(f"è©³ç´°ãªçµæœã¯ '{result['output_directory']}' ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        print(f"\nâŒ è§£æãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")


if __name__ == "__main__":
    main()

