"""
ãƒ†ãƒ‹ã‚¹ã‚µãƒ¼ãƒ“ã‚¹å‹•ä½œè§£æ - å‹•ç”»å‡¦ç†ã‚µãƒ¼ãƒ“ã‚¹
å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã€æ¤œè¨¼ã€å‰å‡¦ç†æ©Ÿèƒ½
"""

import cv2
import numpy as np
import os
import tempfile
import shutil
from typing import Dict, List, Tuple, Optional, Union
from pathlib import Path
import time


class VideoProcessor:
    """å‹•ç”»å‡¦ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, max_file_size: int = 100 * 1024 * 1024):  # 100MB
        """
        å‹•ç”»å‡¦ç†å™¨ã®åˆæœŸåŒ–

        Args:
            max_file_size: æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰
        """
        self.supported_formats = ['.mov', '.mp4', '.avi', '.mkv', '.wmv']
        self.max_file_size = max_file_size
        self.temp_dir = tempfile.mkdtemp(prefix='tennis_analyzer_')

        # å‹•ç”»å“è³ªè¨­å®š
        self.target_fps = 30
        self.target_resolution = (1280, 720)  # HDè§£åƒåº¦
        self.max_duration = 30  # æœ€å¤§30ç§’

        # å‰å‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè¿½åŠ ï¼‰
        self.frame_skip = 5    # 5ãƒ•ãƒ¬ãƒ¼ãƒ ã«1ãƒ•ãƒ¬ãƒ¼ãƒ æ®‹ã™
        self.scale = 0.3       # è§£åƒåº¦30%ã«ç¸®å°

    def __del__(self):
        """ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ - ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if hasattr(self, 'temp_dir') and os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir, ignore_errors=True)

    def validate_video(self, file_path: str) -> Dict[str, Union[bool, str, Dict]]:
        """
        å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
        """
        validation_result = {
            'is_valid': False,
            'error_message': '',
            'warnings': [],
            'metadata': {}
        }

        try:
            if not os.path.exists(file_path):
                validation_result['error_message'] = 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“'
                return validation_result

            file_size = os.path.getsize(file_path)
            if file_size > self.max_file_size:
                validation_result['error_message'] = f'ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ï¼ˆæœ€å¤§: {self.max_file_size // (1024*1024)}MBï¼‰'
                return validation_result

            file_extension = Path(file_path).suffix.lower()
            if file_extension not in self.supported_formats:
                validation_result['error_message'] = f'ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ï¼ˆå¯¾å¿œå½¢å¼: {", ".join(self.supported_formats)}ï¼‰'
                return validation_result

            metadata = self.get_video_metadata(file_path)
            if not metadata:
                validation_result['error_message'] = 'å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“'
                return validation_result

            validation_result['metadata'] = metadata

            if metadata['duration'] > self.max_duration:
                validation_result['warnings'].append(f'å‹•ç”»ãŒé•·ã™ãã¾ã™ï¼ˆæ¨å¥¨: {self.max_duration}ç§’ä»¥ä¸‹ï¼‰')

            if metadata['width'] < 640 or metadata['height'] < 480:
                validation_result['warnings'].append('è§£åƒåº¦ãŒä½ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆæ¨å¥¨: 640x480ä»¥ä¸Šï¼‰')

            if metadata['fps'] < 15:
                validation_result['warnings'].append('ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆãŒä½ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆæ¨å¥¨: 15fpsä»¥ä¸Šï¼‰')

            if metadata['frame_count'] < 30:
                validation_result['warnings'].append('å‹•ç”»ãŒçŸ­ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆæ¨å¥¨: 1ç§’ä»¥ä¸Šï¼‰')

            validation_result['is_valid'] = True

        except Exception as e:
            validation_result['error_message'] = f'æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'

        return validation_result

    def get_video_metadata(self, video_path: str) -> Optional[Dict]:
        """
        å‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        """
        try:
            cap = cv2.VideoCapture(video_path)

            if not cap.isOpened():
                return None

            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

            duration = frame_count / fps if fps > 0 else 0
            file_size = os.path.getsize(video_path)
            file_name = os.path.basename(video_path)

            cap.release()

            return {
                'filename': file_name,
                'file_size': file_size,
                'width': width,
                'height': height,
                'fps': fps,
                'frame_count': frame_count,
                'duration': duration,
                'aspect_ratio': width / height if height > 0 else 0,
                'bitrate': (file_size * 8) / duration if duration > 0 else 0
            }

        except Exception as e:
            print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def preprocess_video(self, video_path: str, output_path: Optional[str] = None) -> str:
        """
        å‹•ç”»ã®å‰å‡¦ç†ï¼ˆãƒªã‚µã‚¤ã‚ºï¼‹é–“å¼•ãï¼‰
        """
        if output_path is None:
            output_path = os.path.join(self.temp_dir, f"preprocessed_{int(time.time())}.mp4")

        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            raise ValueError(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“: {video_path}")

        original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        original_fps = cap.get(cv2.CAP_PROP_FPS)

        # å‡ºåŠ›è¨­å®š
        output_fps = original_fps / self.frame_skip if original_fps > 0 else 10.0
        output_width = int(original_width * self.scale)
        output_height = int(original_height * self.scale)

        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, output_fps, (output_width, output_height))

        frame_count = 0
        kept_frames = 0
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                # ãƒ•ãƒ¬ãƒ¼ãƒ é–“å¼•ã
                if frame_count % self.frame_skip == 0:
                    resized_frame = cv2.resize(frame, (output_width, output_height))
                    enhanced_frame = self._enhance_frame_quality(resized_frame)
                    out.write(enhanced_frame)
                    kept_frames += 1

                frame_count += 1

                if kept_frames % 30 == 0:
                    progress = (frame_count / total_frames) * 100
                    print(f"å‰å‡¦ç†é€²æ—: {progress:.1f}% ({kept_frames}ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜)")

        finally:
            cap.release()
            out.release()

        print(f"âœ… å‰å‡¦ç†å®Œäº†: {output_path}")
        print(f"ğŸ“Š å…ƒãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_frames}, ä¿å­˜ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {kept_frames}")
        print(f"ğŸ†• æ–°FPS: {output_fps:.2f}, æ–°è§£åƒåº¦: {output_width}x{output_height}")

        return output_path

    def _enhance_frame_quality(self, frame: np.ndarray) -> np.ndarray:
        """ãƒ•ãƒ¬ãƒ¼ãƒ å“è³ªã®å‘ä¸Š"""
        denoised = cv2.bilateralFilter(frame, 9, 75, 75)
        lab = cv2.cvtColor(denoised, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        l = clahe.apply(l)
        enhanced = cv2.merge([l, a, b])
        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
        return enhanced
